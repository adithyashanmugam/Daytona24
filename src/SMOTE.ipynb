{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = tf.keras.utils\n",
    "df1 = pd.read_csv('../data/2020/20_agg_data.csv')\n",
    "df2 = pd.read_csv('../data/2019/19_agg_data.csv')\n",
    "df3 = pd.read_csv('../data/2018/18_agg_data.csv')\n",
    "df4 = pd.read_csv('../data/2021/21_agg_data.csv')\n",
    "df_list = [df1, df2, df3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Max Concentration</th>\n",
       "      <th>Last Pit</th>\n",
       "      <th>Air Temp</th>\n",
       "      <th>Track Temp</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11873.000000</td>\n",
       "      <td>11873.000000</td>\n",
       "      <td>11873.000000</td>\n",
       "      <td>11873.000000</td>\n",
       "      <td>11873.000000</td>\n",
       "      <td>11873.000000</td>\n",
       "      <td>11873.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40628.467952</td>\n",
       "      <td>6.720277</td>\n",
       "      <td>51.424450</td>\n",
       "      <td>60.742147</td>\n",
       "      <td>61.618211</td>\n",
       "      <td>2.145229</td>\n",
       "      <td>0.007749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24135.242623</td>\n",
       "      <td>3.043953</td>\n",
       "      <td>17.854547</td>\n",
       "      <td>7.813136</td>\n",
       "      <td>9.732104</td>\n",
       "      <td>2.085498</td>\n",
       "      <td>0.087689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.533049</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>46.400000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19820.000000</td>\n",
       "      <td>4.567957</td>\n",
       "      <td>42.946967</td>\n",
       "      <td>54.899960</td>\n",
       "      <td>55.000040</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40080.000000</td>\n",
       "      <td>6.048387</td>\n",
       "      <td>50.210533</td>\n",
       "      <td>60.400040</td>\n",
       "      <td>62.000060</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>59900.000000</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>54.722600</td>\n",
       "      <td>66.599960</td>\n",
       "      <td>64.999940</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>86440.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>144.666667</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>98.000060</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time  Max Concentration      Last Pit      Air Temp  \\\n",
       "count  11873.000000       11873.000000  11873.000000  11873.000000   \n",
       "mean   40628.467952           6.720277     51.424450     60.742147   \n",
       "std    24135.242623           3.043953     17.854547      7.813136   \n",
       "min       20.000000           0.533049      0.333333     46.400000   \n",
       "25%    19820.000000           4.567957     42.946967     54.899960   \n",
       "50%    40080.000000           6.048387     50.210533     60.400040   \n",
       "75%    59900.000000           8.333333     54.722600     66.599960   \n",
       "max    86440.000000          33.333333    144.666667     77.000000   \n",
       "\n",
       "         Track Temp    Wind Speed        Yellow  \n",
       "count  11873.000000  11873.000000  11873.000000  \n",
       "mean      61.618211      2.145229      0.007749  \n",
       "std        9.732104      2.085498      0.087689  \n",
       "min       32.000000      0.000000      0.000000  \n",
       "25%       55.000040      0.600000      0.000000  \n",
       "50%       62.000060      1.300000      0.000000  \n",
       "75%       64.999940      3.200000      0.000000  \n",
       "max       98.000060     15.100000      1.000000  "
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_df = pd.concat(df_list)\n",
    "comb_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 11873\n",
      "    Positive: 92 (0.77% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(comb_df['Yellow'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.50\n",
      "Weight for class 1: 64.53\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 =  (1 / neg)*(total)/2.0 \n",
    "weight_for_1 =  (1 / pos)*(total)/2.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None, dropout=0.5, input_shape=(3,)):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    model = keras.Sequential([\n",
    "      keras.layers.Dense(\n",
    "          256, activation='relu',\n",
    "          input_shape=input_shape),\n",
    "      keras.layers.Dropout(dropout),\n",
    "      keras.layers.Dense(1, activation='sigmoid',\n",
    "                         bias_initializer=output_bias),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "      optimizer=keras.optimizers.Adam(lr=.001),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_bias = np.log([pos/neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(output_bias=initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = '../data/inital_weights'\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, label, n):\n",
    "  # Use a log scale on y-axis to show the wide range of values.\n",
    "  plt.semilogy(history.epoch, history.history['loss'],\n",
    "               color=colors[n], label='Train ' + label)\n",
    "  plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "               color=colors[n], label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    metrics = ['loss', 'auc', 'precision', 'recall']\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(2,2,n+1)\n",
    "        plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_'+metric],\n",
    "                 color=colors[0], linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == 'auc':\n",
    "            plt.ylim([0.4,.8])\n",
    "        else:\n",
    "            plt.ylim([-0.1,1])\n",
    "\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    print('Green Flags Predicted (True Negatives): ', cm[0][0])\n",
    "    print('Yellow Flags Incorrectly Predicted (False Positives): ', cm[0][1])\n",
    "    print('Yellow Flags Missed (False Negatives): ', cm[1][0])\n",
    "    print('Yellow Flags Correctly Predicted (True Positives): ', cm[1][1])\n",
    "    print('Total Yellow Flags: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
    "\n",
    "    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "    plt.xlim([-0.5,100])\n",
    "    plt.ylim([0,100.5])\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on df 4\n"
     ]
    }
   ],
   "source": [
    "# for i in range(0, 4):\n",
    "i=3\n",
    "df1 = pd.read_csv('../data/2020/20_agg_data.csv')\n",
    "df2 = pd.read_csv('../data/2019/19_agg_data.csv')\n",
    "df3 = pd.read_csv('../data/2018/18_agg_data.csv')\n",
    "df4 = pd.read_csv('../data/2021/21_agg_data.csv')\n",
    "df_list = [df1, df2, df3, df4]\n",
    "\n",
    "print('Testing on df', str(i+1))\n",
    "test_df = df_list[i]\n",
    "test_df.pop('Time')\n",
    "if(i != 3):\n",
    "    test_df.pop('Max Concentration')\n",
    "test_df.pop('Air Temp')\n",
    "\n",
    "train_list = df_list[:i] + df_list[i+1:]\n",
    "train_df = pd.concat(train_list) \n",
    "train_df.pop('Time')\n",
    "train_df.pop('Max Concentration')\n",
    "train_df.pop('Air Temp')\n",
    "\n",
    "eps = 0.001 \n",
    "train_df['Last Pit'] = np.log(train_df['Last Pit']+eps)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Yellow'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val_df.pop('Yellow'))\n",
    "test_labels = np.array(test_df.pop('Yellow'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)\n",
    "\n",
    "\n",
    "# Standard Scale and clip\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "val_features = scaler.transform(val_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "train_features = np.clip(train_features, -5, 5)\n",
    "val_features = np.clip(val_features, -5, 5)\n",
    "test_features = np.clip(test_features, -5, 5)\n",
    "\n",
    "# SMOTE transformd\n",
    "oversample = SMOTE()\n",
    "\n",
    "train_features, train_labels = oversample.fit_resample(train_features, train_labels)\n",
    "val_features, val_labels = oversample.fit_resample(val_features, val_labels)\n",
    "\n",
    "# Run model\n",
    "SMOTE_model = make_model(dropout=0.998, input_shape=(train_features.shape[-1],))\n",
    "SMOTE_model.load_weights(initial_weights)\n",
    "\n",
    "\n",
    "SMOTE_history = SMOTE_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=(val_features, val_labels),\n",
    "    verbose=0,\n",
    "    class_weight=class_weight\n",
    ")\n",
    "\n",
    "# plots\n",
    "plot_metrics(SMOTE_history)\n",
    "train_predictions_SMOTE = SMOTE_model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_SMOTE = SMOTE_model.predict(test_features, batch_size=BATCH_SIZE)\n",
    "\n",
    "SMOTE_results = SMOTE_model.evaluate(test_features, test_labels,\n",
    "                                         batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(SMOTE_model.metrics_names, SMOTE_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "plt.show()\n",
    "\n",
    "plot_cm(test_labels, test_predictions_SMOTE)\n",
    "plt.show()\n",
    "\n",
    "plot_roc(\"Train Resampled\", train_labels, train_predictions_SMOTE, color=colors[2])\n",
    "plot_roc(\"Test Resampled\", test_labels, test_predictions_SMOTE, color=colors[2], linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
